{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c37992ab",
      "metadata": {
        "id": "c37992ab"
      },
      "source": [
        "Feature extraction and creation of datafiles for private competition DML&ML 2023.\n",
        "\n",
        "Source of feature extraction Python code: https://www.kaggle.com/code/yunsuxiaozi/best-feature-engineer-is-all-you-need/notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "438f7e67",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-10-28T01:13:56.985164Z",
          "iopub.status.busy": "2023-10-28T01:13:56.984759Z",
          "iopub.status.idle": "2023-10-28T01:13:57.408397Z",
          "shell.execute_reply": "2023-10-28T01:13:57.407202Z"
        },
        "id": "438f7e67",
        "papermill": {
          "duration": 0.435873,
          "end_time": "2023-10-28T01:13:57.411634",
          "exception": false,
          "start_time": "2023-10-28T01:13:56.975761",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy in c:\\users\\nkalm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.11.3)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.8.1-cp311-cp311-win_amd64.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\nkalm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.26.1)\n",
            "Collecting joblib>=1.1.1 (from scikit-learn)\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.2.0-cp311-cp311-win_amd64.whl.metadata (5.8 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.44.0-cp311-cp311-win_amd64.whl.metadata (156 kB)\n",
            "     ---------------------------------------- 0.0/156.8 kB ? eta -:--:--\n",
            "     -------------------------------------- 156.8/156.8 kB 4.6 MB/s eta 0:00:00\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.5-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\nkalm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (23.1)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Downloading Pillow-10.1.0-cp311-cp311-win_amd64.whl.metadata (9.6 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Downloading pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nkalm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\nkalm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Downloading scikit_learn-1.3.2-cp311-cp311-win_amd64.whl (9.2 MB)\n",
            "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.4/9.2 MB 12.2 MB/s eta 0:00:01\n",
            "   -- ------------------------------------- 0.6/9.2 MB 13.3 MB/s eta 0:00:01\n",
            "   ----- ---------------------------------- 1.2/9.2 MB 11.0 MB/s eta 0:00:01\n",
            "   ------- -------------------------------- 1.6/9.2 MB 10.4 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 2.1/9.2 MB 10.1 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 2.5/9.2 MB 10.5 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 2.9/9.2 MB 10.3 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 3.4/9.2 MB 10.3 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 3.8/9.2 MB 10.1 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 4.1/9.2 MB 9.8 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 4.4/9.2 MB 9.7 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 4.8/9.2 MB 9.5 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 5.2/9.2 MB 9.6 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 5.4/9.2 MB 9.1 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 5.7/9.2 MB 9.0 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 5.7/9.2 MB 8.9 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 5.7/9.2 MB 8.9 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 5.9/9.2 MB 7.9 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 6.1/9.2 MB 7.6 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 6.4/9.2 MB 7.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 6.7/9.2 MB 7.7 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 7.2/9.2 MB 7.8 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 7.5/9.2 MB 7.9 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 7.9/9.2 MB 7.9 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 8.3/9.2 MB 7.9 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 8.6/9.2 MB 8.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  9.0/9.2 MB 8.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.2/9.2 MB 7.8 MB/s eta 0:00:00\n",
            "Downloading matplotlib-3.8.1-cp311-cp311-win_amd64.whl (7.6 MB)\n",
            "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.5/7.6 MB 9.4 MB/s eta 0:00:01\n",
            "   ---- ----------------------------------- 0.9/7.6 MB 10.9 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 1.2/7.6 MB 9.7 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 1.6/7.6 MB 9.4 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 2.0/7.6 MB 10.0 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 2.5/7.6 MB 9.8 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 2.9/7.6 MB 9.8 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 3.3/7.6 MB 9.6 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 3.7/7.6 MB 10.0 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 4.1/7.6 MB 9.7 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 4.5/7.6 MB 9.9 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 4.8/7.6 MB 9.5 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 5.2/7.6 MB 9.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 5.6/7.6 MB 9.7 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 6.0/7.6 MB 9.7 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 6.4/7.6 MB 9.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 6.7/7.6 MB 9.8 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 7.1/7.6 MB 9.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  7.5/7.6 MB 9.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.6/7.6 MB 9.4 MB/s eta 0:00:00\n",
            "Downloading contourpy-1.2.0-cp311-cp311-win_amd64.whl (187 kB)\n",
            "   ---------------------------------------- 0.0/187.6 kB ? eta -:--:--\n",
            "   ---------------------------------------- 187.6/187.6 kB 5.7 MB/s eta 0:00:00\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.44.0-cp311-cp311-win_amd64.whl (2.1 MB)\n",
            "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 0.3/2.1 MB 9.9 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 0.6/2.1 MB 8.1 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.0/2.1 MB 7.7 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 1.4/2.1 MB 8.6 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 1.7/2.1 MB 8.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.1/2.1 MB 8.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.1/2.1 MB 7.6 MB/s eta 0:00:00\n",
            "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 302.2/302.2 kB 9.1 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.5-cp311-cp311-win_amd64.whl (56 kB)\n",
            "   ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 56.1/56.1 kB 2.9 MB/s eta 0:00:00\n",
            "Downloading Pillow-10.1.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
            "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 0.4/2.6 MB 12.9 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 0.8/2.6 MB 9.7 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.2/2.6 MB 9.8 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 1.7/2.6 MB 9.8 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 2.0/2.6 MB 9.3 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.5/2.6 MB 9.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.6/2.6 MB 8.8 MB/s eta 0:00:00\n",
            "Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "   ---------------------------------------- 0.0/103.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 103.1/103.1 kB 5.8 MB/s eta 0:00:00\n",
            "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: threadpoolctl, pyparsing, pillow, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, matplotlib\n",
            "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.44.0 joblib-1.3.2 kiwisolver-1.4.5 matplotlib-3.8.1 pillow-10.1.0 pyparsing-3.1.1 scikit-learn-1.3.2 threadpoolctl-3.2.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -U scikit-learn scipy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8365cd7c",
      "metadata": {
        "id": "8365cd7c"
      },
      "outputs": [],
      "source": [
        "#Names of input and output files\n",
        "#PLEASE ADAPT THE PATHS TO YOUR LOCAL CIRCUMSTANCES!!!\n",
        "\n",
        "#Input files, which you have to download from the public competition\n",
        "train_logs_file = R\"train_logs.csv\"\n",
        "train_scores_file = R\"train_scores.csv\"\n",
        "\n",
        "#Output files, which are created for you by this script to use in the private competition\n",
        "X_train_file = R\"pc_X_train.csv\"\n",
        "y_train_file = R\"pc_y_train.csv\"\n",
        "X_test_file = R\"pc_X_test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "wiNkxZzqpe-i",
      "metadata": {
        "id": "wiNkxZzqpe-i"
      },
      "outputs": [],
      "source": [
        "def create_length_value(source_df, target_df, column_name):\n",
        "    target_df[f'length_{column_name}'] = source_df[column_name].apply(lambda x:len(str(x)))\n",
        "\n",
        "def create_mean_value(source_df, target_df, column_name):\n",
        "    target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
        "\n",
        "def create_std_value(source_df, target_df, column_name):\n",
        "    target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
        "\n",
        "def create_max_value(source_df, target_df, column_name):\n",
        "    target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
        "\n",
        "def create_sum_value(source_df, target_df, column_name):\n",
        "    target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
        "\n",
        "def create_count_value(source_df, target_df, column_name):\n",
        "    target_df[f'count_{column_name}'] = source_df[column_name].groupby([source_df['id']]).count().values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "06icPQ6LC-_F",
      "metadata": {
        "id": "06icPQ6LC-_F"
      },
      "outputs": [],
      "source": [
        "def add_columns(source_df, target_df, column_name_1, column_name_2):\n",
        "    new_column_name = f'{column_name_1}+{column_name_2}'\n",
        "    target_df[new_column_name] = source_df[column_name_1]+source_df[column_name_2]\n",
        "    return new_column_name\n",
        "\n",
        "def diff_columns(source_df, target_df, column_name_1, column_name_2):\n",
        "    new_column_name = f'{column_name_1}-{column_name_2}'\n",
        "    target_df[new_column_name] = source_df[column_name_1]-source_df[column_name_2]\n",
        "    return new_column_name\n",
        "\n",
        "def multiply_columns(source_df, target_df, column_name_1, column_name_2):\n",
        "    new_column_name = f'{column_name_1}*{column_name_2}'\n",
        "    target_df[new_column_name] = source_df[column_name_1]*source_df[column_name_2]\n",
        "    return new_column_name\n",
        "\n",
        "def div_columns(source_df, target_df, column_name_1, column_name_2):\n",
        "    new_column_name = f'{column_name_1}/{column_name_2}'\n",
        "    target_df[new_column_name] = source_df[column_name_1]/source_df[column_name_2]\n",
        "    return new_column_name\n",
        "\n",
        "def concat_columns(source_df, target_df, columns, new_column_name=''):\n",
        "    if not new_column_name:\n",
        "      new_column_name = '_'.join(columns)\n",
        "    target_df[new_column_name] = sum([source_df[column] for column in columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "GqDsF4MG9cOU",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-28T01:14:18.590714Z",
          "iopub.status.busy": "2023-10-28T01:14:18.590228Z",
          "iopub.status.idle": "2023-10-28T01:25:47.006713Z",
          "shell.execute_reply": "2023-10-28T01:25:47.005262Z"
        },
        "id": "GqDsF4MG9cOU",
        "papermill": {
          "duration": 688.435015,
          "end_time": "2023-10-28T01:25:47.016050",
          "exception": false,
          "start_time": "2023-10-28T01:14:18.581035",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Function for feature extraction\n",
        "def deal_df(df):\n",
        "    # event_id of no use,drop.\n",
        "    df.drop(['event_id'],axis=1,inplace=True)\n",
        "\n",
        "    # id\n",
        "    id=df['id'].unique()\n",
        "    feature_df = pd.DataFrame({ \"id\":id })\n",
        "\n",
        "    #down_time, up_time\n",
        "    for column_name in ['down_time', 'up_time']:\n",
        "        create_mean_value(df, feature_df, column_name)\n",
        "        create_std_value(df, feature_df, column_name)\n",
        "        create_max_value(df, feature_df, column_name)\n",
        "        create_sum_value(df, feature_df, column_name)\n",
        "\n",
        "    #length str\n",
        "    for column_name in ['activity', 'down_event', 'up_event', 'text_change']:\n",
        "        create_length_value(df, df, column_name)\n",
        "\n",
        "    for column_name in ['length_activity', 'length_down_event', 'length_up_event', 'length_text_change']:\n",
        "        create_mean_value(df, feature_df, column_name)\n",
        "        create_std_value(df, feature_df, column_name)\n",
        "        create_sum_value(df, feature_df, column_name)\n",
        "\n",
        "    #+ - */\n",
        "\n",
        "    column_pairs = [\n",
        "        ('length_activity', 'length_down_event'),\n",
        "        ('length_activity', 'length_up_event'),\n",
        "        ('length_activity', 'length_text_change'),\n",
        "        ('length_down_event', 'length_up_event'),\n",
        "        ('length_down_event', 'length_text_change'),\n",
        "        ('length_up_event', 'length_text_change'),\n",
        "    ]\n",
        "\n",
        "    for column_pair in column_pairs:\n",
        "      added_column = add_columns(df, df, column_pair[0], column_pair[1])\n",
        "      create_mean_value(df, feature_df, added_column)\n",
        "      create_std_value(df, feature_df, added_column)\n",
        "      create_sum_value(df, feature_df, added_column)\n",
        "\n",
        "      diff_column = diff_columns(df, df, column_pair[0], column_pair[1])\n",
        "      create_mean_value(df, feature_df, diff_column)\n",
        "      create_std_value(df, feature_df, diff_column)\n",
        "      create_sum_value(df, feature_df, diff_column)\n",
        "\n",
        "      multiplied_column = multiply_columns(df, df, column_pair[0], column_pair[1])\n",
        "      create_mean_value(df, feature_df, multiplied_column)\n",
        "      create_std_value(df, feature_df, multiplied_column)\n",
        "      create_sum_value(df, feature_df, multiplied_column)\n",
        "\n",
        "      div_column = div_columns(df, df, column_pair[0], column_pair[1])\n",
        "      create_mean_value(df, feature_df, div_column)\n",
        "      create_std_value(df, feature_df, div_column)\n",
        "      create_max_value(df, feature_df, div_column)\n",
        "      create_sum_value(df, feature_df, div_column)\n",
        "\n",
        "\n",
        "    #Extract 4 features.\n",
        "    concat_columns(df, df, ['length_activity', 'length_down_event', 'length_up_event', 'length_text_change'], 'total_length')\n",
        "    create_mean_value(df, feature_df, 'total_length')\n",
        "    create_std_value(df, feature_df, 'total_length')\n",
        "    create_max_value(df, feature_df, 'total_length')\n",
        "    create_sum_value(df, feature_df, 'total_length')\n",
        "\n",
        "    #cursion_position+word_count\n",
        "    concat_columns(df, df, ['cursor_position', 'word_count'])\n",
        "    create_mean_value(df, feature_df, 'cursor_position_word_count')\n",
        "    create_std_value(df, feature_df, 'cursor_position_word_count')\n",
        "    create_max_value(df, feature_df, 'cursor_position_word_count')\n",
        "\n",
        "    #time_shift(free_time)\n",
        "    gaps=[1, 2, 5, 7, 10, 14, 21, 30, 50]\n",
        "    for gap in gaps:\n",
        "        df[f'up_time_shift{gap}'] = df.groupby('id')['up_time'].shift(gap)\n",
        "        df[f'free_time{gap}'] = df['down_time'] - df[f'up_time_shift{gap}']\n",
        "        df.drop(f'up_time_shift{gap}', axis=1, inplace=True)\n",
        "\n",
        "        create_mean_value(df, feature_df, f'free_time{gap}')\n",
        "        create_std_value(df, feature_df,  f'free_time{gap}')\n",
        "        create_max_value(df, feature_df, f'free_time{gap}')\n",
        "        create_sum_value(df, feature_df, f'free_time{gap}')\n",
        "        create_count_value(df, feature_df, f'free_time{gap}')\n",
        "\n",
        "        # cursor position shift\n",
        "        df[f'cursor_position_shift{gap}'] = df.groupby('id')['cursor_position'].shift(gap)\n",
        "        df[f'cursor_position_change{gap}'] = df['cursor_position'] - df[f'cursor_position_shift{gap}']\n",
        "        df.drop(f'cursor_position_shift{gap}', axis=1, inplace=True)\n",
        "\n",
        "        create_mean_value(df, feature_df, f'cursor_position_change{gap}')\n",
        "        create_std_value(df, feature_df, f'cursor_position_change{gap}')\n",
        "        create_max_value(df, feature_df, f'cursor_position_change{gap}')\n",
        "        create_sum_value(df, feature_df, f'cursor_position_change{gap}')\n",
        "\n",
        "        # word count shift\n",
        "        df[f'word_count_shift{gap}'] = df.groupby('id')['word_count'].shift(gap)\n",
        "        df[f'word_count_change{gap}'] = df['word_count'] - df[f'word_count_shift{gap}']\n",
        "        df.drop(f'word_count_shift{gap}', axis=1, inplace=True)\n",
        "\n",
        "        create_mean_value(df, feature_df, f'word_count_change{gap}')\n",
        "        create_std_value(df, feature_df, f'word_count_change{gap}')\n",
        "        create_max_value(df, feature_df, f'word_count_change{gap}')\n",
        "        create_sum_value(df, feature_df, f'word_count_change{gap}')\n",
        "\n",
        "        # cursor_position_word_count shift\n",
        "        df[f'cursor_position_word_count_shift{gap}'] = df.groupby('id')['cursor_position_word_count'].shift(gap)\n",
        "        df[f'cursor_position_word_count_change{gap}'] = df['cursor_position_word_count'] - df[f'cursor_position_word_count_shift{gap}']\n",
        "        df.drop(f'cursor_position_word_count_shift{gap}', axis=1, inplace=True)\n",
        "\n",
        "        create_mean_value(df, feature_df, f'cursor_position_word_count_change{gap}')\n",
        "        create_std_value(df, feature_df, f'cursor_position_word_count_change{gap}')\n",
        "        create_max_value(df, feature_df, f'cursor_position_word_count_change{gap}')\n",
        "        create_sum_value(df, feature_df, f'cursor_position_word_count_change{gap}')\n",
        "\n",
        "    #action_time\n",
        "    create_mean_value(df, feature_df, 'action_time')\n",
        "    create_std_value(df, feature_df, 'action_time')\n",
        "    create_sum_value(df, feature_df, 'action_time')\n",
        "    create_count_value(df, feature_df, 'action_time')\n",
        "\n",
        "    feature_df['sum_time']=df['up_time'].groupby([df['id']]).max().values\n",
        "    feature_df['count_action_time_percent']=feature_df['count_action_time']/feature_df['sum_action_time']\n",
        "    feature_df['count_time_percent']=feature_df['count_action_time']/feature_df['sum_time']\n",
        "    feature_df['active_percent']=feature_df['sum_action_time']/feature_df['sum_time']\n",
        "\n",
        "    #cursor_position\n",
        "    create_mean_value(df, feature_df, 'cursor_position')\n",
        "    create_std_value(df, feature_df, 'cursor_position')\n",
        "    create_max_value(df, feature_df, 'cursor_position')\n",
        "    feature_df['cursor_speed']=feature_df['max_cursor_position']/feature_df['sum_action_time']\n",
        "\n",
        "    #word_count\n",
        "    create_mean_value(df, feature_df, 'word_count')\n",
        "    create_std_value(df, feature_df, 'word_count')\n",
        "    create_max_value(df, feature_df, 'word_count')\n",
        "    feature_df['word_count_speed']=feature_df['max_word_count']/feature_df['sum_action_time']\n",
        "\n",
        "\n",
        "    # concat 3 columns\n",
        "\n",
        "    column_lists = [\n",
        "        ('cursor_position', 'word_count', 'length_activity'),\n",
        "        ('cursor_position', 'word_count', 'length_down_event'),\n",
        "        ('cursor_position', 'word_count', 'length_text_change'),\n",
        "        ('length_activity', 'length_down_event', 'length_text_change'),\n",
        "\n",
        "    ]\n",
        "\n",
        "    for columns in column_lists:\n",
        "        concat_columns(df, df, columns)\n",
        "        create_mean_value(df, feature_df, f'{columns[0]}_{columns[1]}_{columns[2]}')\n",
        "        create_std_value(df, feature_df, f'{columns[0]}_{columns[1]}_{columns[2]}')\n",
        "        create_max_value(df, feature_df, f'{columns[0]}_{columns[1]}_{columns[2]}')\n",
        "\n",
        "    # Get activity\n",
        "    activity = df['activity'].value_counts().keys().values\n",
        "\n",
        "    # activity_i_count(bag of words model)\n",
        "    for i in range(len(activity)):\n",
        "        df[f'is_{activity[i]}'] = (df['activity'] == activity[i])\n",
        "        feature_df[f'activity_{i}_count'] = df[f'is_{activity[i]}'].groupby([df['id']]).sum().values\n",
        "        feature_df[f'activity_{i}_mean'] = df[f'is_{activity[i]}'].groupby([df['id']]).mean().values\n",
        "        feature_df[f'activity_{i}_std'] = df[f'is_{activity[i]}'].groupby([df['id']]).std().values\n",
        "\n",
        "    # Take the top 30 important ones\n",
        "    event = df['down_event'].value_counts()[:30].keys().values\n",
        "\n",
        "    # event (bag of words model)\n",
        "    for i in range(len(event)):\n",
        "        df[f'is_{event[i]}'] = (df['down_event'] == event[i])\n",
        "        feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
        "        feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
        "        feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
        "\n",
        "    # down_event The number of occurrences of each letter of\n",
        "    for i in range(26):\n",
        "        feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
        "        for j in range(len(activity)):\n",
        "            word = activity[j].lower()  # For example input\n",
        "            for k in word:\n",
        "                if k == chr(97 + i):\n",
        "                    feature_df[f'event_letter_{i}'] += feature_df[\n",
        "                        f'event_{j}_count']\n",
        "\n",
        "    # Take the top 15 important ones\n",
        "    change = df['text_change'].value_counts()[:15].keys().values\n",
        "\n",
        "    # text_change:bag of words model\n",
        "    for i in range(len(change)):\n",
        "        df[f'is_{change[i]}'] = (df['text_change'] == change[i])\n",
        "        feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
        "        feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
        "        feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
        "\n",
        "    # Classify features with obvious linear correlation.\n",
        "    feature_df['count_action_time_grade2'] = feature_df['count_action_time'] // 500\n",
        "    feature_df['max_cursor_grade2'] = feature_df['max_cursor_position'] // 300\n",
        "    feature_df['max_word_count_grade2'] = feature_df['max_word_count'] // 50\n",
        "\n",
        "    return feature_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "86a75ff3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86a75ff3",
        "outputId": "644a2368-6da4-44b4-a0c9-b236a8ffcb69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'count_{column_name}'] = source_df[column_name].groupby([source_df['id']]).count().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'count_{column_name}'] = source_df[column_name].groupby([source_df['id']]).count().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'count_{column_name}'] = source_df[column_name].groupby([source_df['id']]).count().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'count_{column_name}'] = source_df[column_name].groupby([source_df['id']]).count().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'count_{column_name}'] = source_df[column_name].groupby([source_df['id']]).count().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'count_{column_name}'] = source_df[column_name].groupby([source_df['id']]).count().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'count_{column_name}'] = source_df[column_name].groupby([source_df['id']]).count().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'count_{column_name}'] = source_df[column_name].groupby([source_df['id']]).count().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'count_{column_name}'] = source_df[column_name].groupby([source_df['id']]).count().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'sum_{column_name}'] = source_df[column_name].groupby([source_df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'count_{column_name}'] = source_df[column_name].groupby([source_df['id']]).count().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df['sum_time']=df['up_time'].groupby([df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df['count_action_time_percent']=feature_df['count_action_time']/feature_df['sum_action_time']\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:124: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df['count_time_percent']=feature_df['count_action_time']/feature_df['sum_time']\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df['active_percent']=feature_df['sum_action_time']/feature_df['sum_time']\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:131: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df['cursor_speed']=feature_df['max_cursor_position']/feature_df['sum_action_time']\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:137: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df['word_count_speed']=feature_df['max_word_count']/feature_df['sum_action_time']\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'mean_{column_name}'] = source_df[column_name].groupby([source_df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'std_{column_name}'] = source_df[column_name].groupby([source_df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\2612742836.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  target_df[f'max_{column_name}'] = source_df[column_name].groupby([source_df['id']]).max().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:162: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_count'] = df[f'is_{activity[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_mean'] = df[f'is_{activity[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:164: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_std'] = df[f'is_{activity[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:162: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_count'] = df[f'is_{activity[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_mean'] = df[f'is_{activity[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:164: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_std'] = df[f'is_{activity[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:162: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_count'] = df[f'is_{activity[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_mean'] = df[f'is_{activity[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:164: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_std'] = df[f'is_{activity[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:162: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_count'] = df[f'is_{activity[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_mean'] = df[f'is_{activity[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:164: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_std'] = df[f'is_{activity[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:162: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_count'] = df[f'is_{activity[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_mean'] = df[f'is_{activity[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:164: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_std'] = df[f'is_{activity[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:162: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_count'] = df[f'is_{activity[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:163: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_mean'] = df[f'is_{activity[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:164: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'activity_{i}_std'] = df[f'is_{activity[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:171: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{event[i]}'] = (df['down_event'] == event[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:171: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{event[i]}'] = (df['down_event'] == event[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:171: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{event[i]}'] = (df['down_event'] == event[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:171: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{event[i]}'] = (df['down_event'] == event[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:171: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{event[i]}'] = (df['down_event'] == event[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:171: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{event[i]}'] = (df['down_event'] == event[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:171: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{event[i]}'] = (df['down_event'] == event[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:171: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{event[i]}'] = (df['down_event'] == event[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:171: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{event[i]}'] = (df['down_event'] == event[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:171: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{event[i]}'] = (df['down_event'] == event[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:172: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_count'] = df[f'is_{event[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:173: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_mean'] = df[f'is_{event[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:174: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_{i}_std'] = df[f'is_{event[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'event_letter_{i}'] = 0  # From a to z, case insensitive\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{change[i]}'] = (df['text_change'] == change[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{change[i]}'] = (df['text_change'] == change[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'is_{change[i]}'] = (df['text_change'] == change[i])\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:192: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_count'] = df[f'is_{change[i]}'].groupby([df['id']]).sum().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:193: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_mean'] = df[f'is_{change[i]}'].groupby([df['id']]).mean().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df[f'change_{i}_std'] = df[f'is_{change[i]}'].groupby([df['id']]).std().values\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:197: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df['count_action_time_grade2'] = feature_df['count_action_time'] // 500\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:198: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df['max_cursor_grade2'] = feature_df['max_cursor_position'] // 300\n",
            "C:\\Users\\nkalm\\AppData\\Local\\Temp\\ipykernel_6764\\1881910482.py:199: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  feature_df['max_word_count_grade2'] = feature_df['max_word_count'] // 50\n"
          ]
        }
      ],
      "source": [
        "# Read data files from the public Kaggle competition!\n",
        "train_logs = pd.read_csv(train_logs_file)\n",
        "train_scores = pd.read_csv(train_scores_file)\n",
        "\n",
        "# Strip position values for \"Move from\" activities\n",
        "train_logs['activity'] = train_logs['activity'].apply(lambda x: \"Move From\" if str(x)[:9] == \"Move From\" else x)\n",
        "\n",
        "# Call feature extraction function\n",
        "# If the performance warning bothers you, check https://stackoverflow.com/questions/68292862/performancewarning-dataframe-is-highly-fragmented-this-is-usually-the-result-o\n",
        "train_df = deal_df(train_logs)\n",
        "\n",
        "# Merge X and y on id\n",
        "train_df = pd.merge(train_df, train_scores, on=\"id\", how=\"left\")\n",
        "train_df.drop(['id'], axis=1, inplace=True)\n",
        "X = train_df.drop(['score'], axis=1)\n",
        "y = train_df['score']\n",
        "\n",
        "# Split up dataset;\n",
        "# It is not allowed to use y_test!!! -- If you use it, you are disqualified from the assignment!!!\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "# Save  training set X, y  and test set X\n",
        "# It is not allowed to use y_test!!! -- If you use it, you are disqualified from the assignment!!!\n",
        "X_train.reset_index(drop=True, inplace=True)\n",
        "y_train.reset_index(drop=True, inplace=True)\n",
        "X_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Write data files for the private Kaggle competition!\n",
        "X_train.to_csv(X_train_file, index_label=\"id\")\n",
        "y_train.to_csv(y_train_file, index_label=\"id\")\n",
        "X_test.to_csv(X_test_file, index_label=\"id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn.linear_model as LinearRegression\n",
        "import sklearn.model_selection as model_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_file = R\"pc_y_test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_baseline = pd.read_csv(X_train_file,index_col=\"id\")\n",
        "y_train_baseline = pd.read_csv(y_train_file,index_col=\"id\")\n",
        "X_test_baseline = pd.read_csv(X_test_file,index_col=\"id\")\n",
        "\n",
        "model = LinearRegression.LinearRegression()\n",
        "\n",
        "model.fit(X_train_baseline, y_train_baseline)\n",
        "y_test_baseline = model.predict(X_test_baseline)\n",
        "pd.DataFrame(y_test_baseline, columns= [\"score\"]).to_csv(y_test_file, index_label=\"id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load the training data\n",
        "X_train = pd.read_csv('pc_X_train.csv', index_col='id')\n",
        "y_train = pd.read_csv('pc_y_train.csv', index_col='id')\n",
        "\n",
        "# Train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Load the test data\n",
        "X_test = pd.read_csv('pc_X_test.csv', index_col='id')\n",
        "\n",
        "# Predict the scores for the test data\n",
        "y_test = model.predict(X_test)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "pd.DataFrame(y_test, columns=['score'], index=X_test.index).to_csv('final_predictions.csv', index_label='id')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation MSE: 1.29\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the training data\n",
        "x_train = pd.read_csv('pc_X_train.csv', index_col='id')\n",
        "y_train = pd.read_csv('pc_y_train.csv', index_col='id')\n",
        "x_test = pd.read_csv('pc_X_test.csv', index_col='id')\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
        "\n",
        "# Train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_val_prediction = model.predict(x_val)\n",
        "mse = mean_squared_error(y_val, y_val_prediction)\n",
        "print(f\"Validation MSE: {mse:.2f}\")\n",
        "\n",
        "# # Tune the model hyperparameters\n",
        "# param_grid = {'fit_intercept': [True, False], 'copy_X': [True, False], 'positive': [True, False]}\n",
        "# grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "# grid_search.fit(x_train, y_train)\n",
        "# print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Train the final model on the entire training set using the best hyperparameters\n",
        "# model = LinearRegression()\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the test set\n",
        "y_prediction = model.predict(x_test)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "pd.DataFrame(y_prediction, columns=['score']).to_csv('lineal_regression.csv', index_label='id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation MSE: 0.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nkalm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.708e+02, tolerance: 1.713e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the training data\n",
        "x_train = pd.read_csv('pc_X_train.csv', index_col='id')\n",
        "y_train = pd.read_csv('pc_y_train.csv', index_col='id')\n",
        "x_test = pd.read_csv('pc_X_test.csv', index_col='id')\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
        "\n",
        "# Train a lasso model\n",
        "model = Lasso()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "y_validation = model.predict(x_val)\n",
        "\n",
        "mse = mean_squared_error(y_val, y_validation)\n",
        "print(f\"Validation MSE: {mse:.2f}\")\n",
        "\n",
        "y_prediction = model.predict(x_test)\n",
        "pd.DataFrame(y_prediction, columns=['score']).to_csv('lasso.csv', index_label='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation MSE: 0.52\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Load the datasets\n",
        "x_train = pd.read_csv('pc_X_train.csv', index_col='id')\n",
        "y_train = pd.read_csv('pc_y_train.csv', index_col='id')\n",
        "x_test = pd.read_csv('pc_X_test.csv', index_col='id')\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
        "\n",
        "# Train an XGBoost model on the training set\n",
        "model = XGBRegressor()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Validate the model on the validation set\n",
        "y_validation = model.predict(x_val)\n",
        "mse = mean_squared_error(y_val, y_validation)\n",
        "print(f\"Validation MSE: {mse:.2f}\")\n",
        "\n",
        "# Predict the target variable for the test set\n",
        "y_test_pred = model.predict(x_test)\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "pd.DataFrame(y_test_pred, columns=['score']).to_csv('xgboost_predictions.csv', index_label='id')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 3078.48706,
      "end_time": "2023-10-28T02:05:11.708868",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-10-28T01:13:53.221808",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
